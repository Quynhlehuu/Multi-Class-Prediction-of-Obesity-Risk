{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9565c156",
   "metadata": {},
   "source": [
    "# IMPORT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3086324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "356dc5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"X_train.csv\")\n",
    "y = pd.read_csv(\"y_train.csv\")\n",
    "test = pd.read_csv(\"X_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0e63180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20758, 17)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3d91a0",
   "metadata": {},
   "source": [
    "# DATA SCALAR AND SPLITTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a07a868",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "test = scaler.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40de95c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0041516 ,  0.10569857, -0.00282826, ...,  0.47128803,\n",
       "        -0.23216606, -0.35887678],\n",
       "       [-0.99586557, -1.0270519 , -1.60629083, ..., -1.63984638,\n",
       "         1.72213368, -0.98169796],\n",
       "       [-0.99586557, -1.0270519 ,  0.12845138, ..., -1.63984638,\n",
       "        -0.23216606, -1.60451914],\n",
       "       ...,\n",
       "       [ 1.0041516 , -0.65766899,  1.36653688, ..., -1.63984638,\n",
       "        -0.23216606,  0.2639444 ],\n",
       "       [ 1.0041516 ,  1.76006735, -0.00280536, ..., -1.63984638,\n",
       "         1.72213368, -0.35887678],\n",
       "       [ 1.0041516 ,  0.49905134,  1.33206194, ...,  0.47128803,\n",
       "        -0.23216606,  0.88676559]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c204ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92e8234b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train set: (16606, 17)\n",
      "Shape of test set: (4152, 17)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=7\n",
    ")\n",
    "\n",
    "print(\"Shape of train set:\", X_train.shape)\n",
    "print(\"Shape of test set:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a54787d",
   "metadata": {},
   "source": [
    "# MODELLING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d4137c",
   "metadata": {},
   "source": [
    "### IMPORT METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9faf22ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf4d2092",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f1_scores = {'train':{'KNN': 0, 'DT': 0, 'RF': 0, 'LR': 0, 'NN': 0, 'EN_HARD': 0, 'EN_SOFT': 0},\n",
    "             'test':{'KNN': 0, 'DT': 0, 'RF': 0, 'LR': 0, 'NN': 0, 'EN_HARD': 0, 'EN_SOFT': 0}}\n",
    "jaccard_scores = {'train':{'KNN': 0, 'DT': 0, 'RF': 0, 'LR': 0, 'NN': 0, 'EN_HARD': 0, 'EN_SOFT': 0}, \n",
    "                  'test':{'KNN': 0, 'DT': 0, 'RF': 0, 'LR': 0, 'NN': 0, 'EN_HARD': 0, 'EN_SOFT': 0}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4cdbef",
   "metadata": {},
   "source": [
    "### K Nearest Neighbor(KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08fce461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bf3e5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best param_grid:\n",
      "{'metric': 'euclidean', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "f1 score on train set: 1.0\n",
      "f1 score on test set: 0.733456445371721\n",
      "Jaccard score on train set: 1.0\n",
      "Jaccard score on test set: 0.6085192678205634\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_grid = {\n",
    "    \"n_neighbors\":range(1, 5),\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"metric\": [\"euclidean\", \"manhattan\", \"chebyshev\"],\n",
    "}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "grid_search_knn = GridSearchCV(knn, param_grid, scoring=\"f1\", cv=5, n_jobs=-1)\n",
    "grid_search_knn.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best param_grid:\")\n",
    "print(grid_search_knn.best_params_)\n",
    "\n",
    "y_pred_train = grid_search_knn.predict(X_train)\n",
    "y_pred_test = grid_search_knn.predict(X_test)\n",
    "\n",
    "f1_score_train = f1_score(y_train, y_pred_train, average='macro')\n",
    "f1_score_test = f1_score(y_test, y_pred_test, average='macro')\n",
    "jaccard_score_train = jaccard_score(y_train, y_pred_train, average='macro')\n",
    "jaccard_score_test = jaccard_score(y_test, y_pred_test, average='macro')\n",
    "\n",
    "f1_scores[\"train\"][\"KNN\"] = f1_score_train\n",
    "f1_scores[\"test\"][\"KNN\"] = f1_score_test\n",
    "jaccard_scores[\"train\"][\"KNN\"] = jaccard_score_train\n",
    "jaccard_scores[\"test\"][\"KNN\"] = jaccard_score_test\n",
    "\n",
    "print(\"f1 score on train set:\", f1_score_train)\n",
    "print(\"f1 score on test set:\", f1_score_test)\n",
    "print(\"Jaccard score on train set:\", jaccard_score_train)\n",
    "print(\"Jaccard score on test set:\", jaccard_score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdd01ab",
   "metadata": {},
   "source": [
    "### Decision Tree(DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fba3f35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b738c7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best param_grid:\n",
      "{'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "f1 score on train set: 0.8378258598569124\n",
      "f1 score on test set: 0.8273167373689274\n",
      "Jaccard score on train setn: 0.7368753648912393\n",
      "Jaccard score on test set: 0.7225172336218805\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": range(5, 10),\n",
    "    \"min_samples_split\": range(2, 5),\n",
    "    \"min_samples_leaf\": range(1, 5),\n",
    "}\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "grid_search_dt = GridSearchCV(dt, param_grid, scoring=\"f1\", cv=5, n_jobs=-1)\n",
    "grid_search_dt.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best param_grid:\")\n",
    "print(grid_search_dt.best_params_)\n",
    "\n",
    "y_pred_train = grid_search_dt.predict(X_train)\n",
    "y_pred_test = grid_search_dt.predict(X_test)\n",
    "\n",
    "f1_score_train = f1_score(y_train, y_pred_train, average='macro')\n",
    "f1_score_test = f1_score(y_test, y_pred_test, average='macro')\n",
    "jaccard_score_train = jaccard_score(y_train, y_pred_train, average='macro')\n",
    "jaccard_score_test = jaccard_score(y_test, y_pred_test, average='macro')\n",
    "\n",
    "f1_scores[\"train\"][\"DT\"] = f1_score_train\n",
    "f1_scores[\"test\"][\"DT\"] = f1_score_test\n",
    "jaccard_scores[\"train\"][\"DT\"] = jaccard_score_train\n",
    "jaccard_scores[\"test\"][\"DT\"] = jaccard_score_test\n",
    "\n",
    "print(\"f1 score on train set:\", f1_score_train)\n",
    "print(\"f1 score on test set:\", f1_score_test)\n",
    "print(\"Jaccard score on train setn:\", jaccard_score_train)\n",
    "print(\"Jaccard score on test set:\", jaccard_score_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7701f269",
   "metadata": {},
   "source": [
    "### Random Forest(RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f1647d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c03c9fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best param_grid :\n",
      "{'criterion': 'gini', 'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "f1 score on train set: 0.894828295747951\n",
      "f1 score on test set: 0.8754399452253081\n",
      "Jaccard score on train set: 0.8181063660949012\n",
      "Jaccard score on test set: 0.7875472788896047\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 150],  \n",
    "    \"criterion\": [\"gini\"],\n",
    "    \"max_depth\": range(5, 10),  \n",
    "    \"min_samples_split\": range(2, 5),  \n",
    "    \"min_samples_leaf\": range(1, 5),  \n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "grid_search_rf = GridSearchCV(rf, param_grid, scoring=\"f1_macro\", cv=5, n_jobs=-1)\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best param_grid :\")\n",
    "print(grid_search_rf.best_params_)\n",
    "\n",
    "y_pred_train = grid_search_rf.predict(X_train)\n",
    "y_pred_test = grid_search_rf.predict(X_test)\n",
    "\n",
    "f1_score_train = f1_score(y_train, y_pred_train, average='macro')\n",
    "f1_score_test = f1_score(y_test, y_pred_test, average='macro')\n",
    "jaccard_score_train = jaccard_score(y_train, y_pred_train, average='macro')\n",
    "jaccard_score_test = jaccard_score(y_test, y_pred_test, average='macro')\n",
    "\n",
    "f1_scores[\"train\"][\"RF\"] = f1_score_train\n",
    "f1_scores[\"test\"][\"RF\"] = f1_score_test\n",
    "jaccard_scores[\"train\"][\"RF\"] = jaccard_score_train\n",
    "jaccard_scores[\"test\"][\"RF\"] = jaccard_score_test\n",
    "\n",
    "print(\"f1 score on train set:\", f1_score_train)\n",
    "print(\"f1 score on test set:\", f1_score_test)\n",
    "print(\"Jaccard score on train set:\", jaccard_score_train)\n",
    "print(\"Jaccard score on test set:\", jaccard_score_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92efd062",
   "metadata": {},
   "source": [
    "### Logistic Regression(LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68b7c609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7b54f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "75 fits failed out of a total of 450.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 73, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best param_grid:\n",
      "{'C': 0.001, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "f1 score on train set: 0.6761349100840965\n",
      "f1 score on test set: 0.6755998635835189\n",
      "Jaccard score on train set: 0.5415177074113303\n",
      "Jaccard score on test set: 0.54131892574617\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_grid = {\n",
    "    'penalty': [ 'l2', 'none'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'solver': ['newton-cg',  'liblinear', 'sag'],\n",
    "    'max_iter': [100, 500, 1000]\n",
    "}\n",
    "lr = LogisticRegression()\n",
    "grid_search_lr = GridSearchCV(lr, param_grid, scoring=\"f1\", cv=5, n_jobs=-1)\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best param_grid:\")\n",
    "print(grid_search_lr.best_params_)\n",
    "\n",
    "y_pred_train = grid_search_lr.predict(X_train)\n",
    "y_pred_test = grid_search_lr.predict(X_test)\n",
    "\n",
    "f1_score_train = f1_score(y_train, y_pred_train, average='macro')\n",
    "f1_score_test = f1_score(y_test, y_pred_test, average='macro')\n",
    "jaccard_score_train = jaccard_score(y_train, y_pred_train, average='macro')\n",
    "jaccard_score_test = jaccard_score(y_test, y_pred_test, average='macro')\n",
    "\n",
    "f1_scores[\"train\"][\"LR\"] = f1_score_train\n",
    "f1_scores[\"test\"][\"LR\"] = f1_score_test\n",
    "jaccard_scores[\"train\"][\"LR\"] = jaccard_score_train\n",
    "jaccard_scores[\"test\"][\"LR\"] = jaccard_score_test\n",
    "\n",
    "print(\"f1 score on train set:\", f1_score_train)\n",
    "print(\"f1 score on test set:\", f1_score_test)\n",
    "print(\"Jaccard score on train set:\", jaccard_score_train)\n",
    "print(\"Jaccard score on test set:\", jaccard_score_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4833ee",
   "metadata": {},
   "source": [
    "### Neural Network(NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a7861cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24c5ab22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1102: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best param_grid :\n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (10, 10), 'solver': 'sgd'}\n",
      "f1 score on train set: 0.8546711153851761\n",
      "f1 score on test set: 0.847577753267237\n",
      "Jaccard score on train set: 0.7593993284275681\n",
      "Jaccard score on test set: 0.7489545018255402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_grid = {\n",
    "    \"hidden_layer_sizes\": [(10, 10), (20, 20), (30, 30)],\n",
    "    \"activation\": [\"relu\", \"tanh\", \"identity\"],\n",
    "    \"solver\": [\"sgd\",\"adam\", \"lbfgs\"],\n",
    "    \"alpha\": [0.0001, 0.001, 0.01]  \n",
    "}\n",
    "\n",
    "nn = MLPClassifier()\n",
    "grid_search_nn = GridSearchCV(nn, param_grid, scoring=\"f1\", cv=5, n_jobs=-1)\n",
    "grid_search_nn.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best param_grid :\")\n",
    "print(grid_search_nn.best_params_)\n",
    "\n",
    "y_pred_train = grid_search_nn.predict(X_train)\n",
    "y_pred_test = grid_search_nn.predict(X_test)\n",
    "\n",
    "f1_score_train = f1_score(y_train, y_pred_train, average='macro')\n",
    "f1_score_test = f1_score(y_test, y_pred_test, average='macro')\n",
    "jaccard_score_train = jaccard_score(y_train, y_pred_train, average='macro')\n",
    "jaccard_score_test = jaccard_score(y_test, y_pred_test, average='macro')\n",
    "\n",
    "f1_scores[\"train\"][\"NN\"] = f1_score_train\n",
    "f1_scores[\"test\"][\"NN\"] = f1_score_test\n",
    "jaccard_scores[\"train\"][\"NN\"] = jaccard_score_train\n",
    "jaccard_scores[\"test\"][\"NN\"] = jaccard_score_test\n",
    "\n",
    "print(\"f1 score on train set:\", f1_score_train)\n",
    "print(\"f1 score on test set:\", f1_score_test)\n",
    "print(\"Jaccard score on train set:\", jaccard_score_train)\n",
    "print(\"Jaccard score on test set:\", jaccard_score_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d67eb8",
   "metadata": {},
   "source": [
    "### Soft Voting Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "536009ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5cd8c47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "C:\\Users\\lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score on train set: 0.9478649362934652\n",
      "f1 score on test set: 0.8740793858478147\n",
      "Jaccard score on train set: 0.9028025707248568\n",
      "Jaccard score on test set: 0.786571434363772\n"
     ]
    }
   ],
   "source": [
    "\n",
    "knn = KNeighborsClassifier(metric='euclidean', n_neighbors=1, weights='uniform')\n",
    "dt = DecisionTreeClassifier(criterion='gini', max_depth=10, min_samples_leaf=1, min_samples_split=2)\n",
    "rf = RandomForestClassifier(criterion= 'gini', max_depth= 10, min_samples_leaf= 1, min_samples_split= 5, n_estimators= 150)\n",
    "lr = LogisticRegression(penalty=\"l2\", C=0.001,max_iter= 100, solver='newton-cg')\n",
    "nn = MLPClassifier(hidden_layer_sizes=(10, 10), activation=\"relu\", solver=\"adam\")\n",
    "\n",
    "ensemble_s = VotingClassifier(estimators=[\n",
    "    (\"knn\", knn),\n",
    "    (\"dt\", dt),\n",
    "    (\"rf\", rf),\n",
    "    (\"lr\", lr),\n",
    "    (\"nn\", nn),\n",
    "], voting=\"soft\")\n",
    "\n",
    "ensemble_s.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = ensemble_s.predict(X_train)\n",
    "y_pred_test = ensemble_s.predict(X_test)\n",
    "\n",
    "f1_score_train = f1_score(y_train, y_pred_train, average='macro')\n",
    "f1_score_test = f1_score(y_test, y_pred_test, average='macro')\n",
    "jaccard_score_train = jaccard_score(y_train, y_pred_train, average='macro')\n",
    "jaccard_score_test = jaccard_score(y_test, y_pred_test, average='macro')\n",
    "\n",
    "f1_scores[\"train\"][\"EN_SOFT\"] = f1_score_train\n",
    "f1_scores[\"test\"][\"EN_SOFT\"] = f1_score_test\n",
    "jaccard_scores[\"train\"][\"EN_SOFT\"] = jaccard_score_train\n",
    "jaccard_scores[\"test\"][\"EN_SOFT\"] = jaccard_score_test\n",
    "\n",
    "# In ra f1 score và Jaccard score\n",
    "print(\"f1 score on train set:\", f1_score_train)\n",
    "print(\"f1 score on test set:\", f1_score_test)\n",
    "print(\"Jaccard score on train set:\", jaccard_score_train)\n",
    "print(\"Jaccard score on test set:\", jaccard_score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb771cb",
   "metadata": {},
   "source": [
    "### Hard Voting Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "057e3e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "C:\\Users\\lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score on train set: 0.9246144820934988\n",
      "f1 score on test set: 0.8766904995092638\n",
      "Jaccard score on train set: 0.8637764879537263\n",
      "Jaccard score on test set: 0.7895504752814233\n"
     ]
    }
   ],
   "source": [
    "\n",
    "knn = KNeighborsClassifier(metric='euclidean', n_neighbors=1, weights='uniform')\n",
    "dt = DecisionTreeClassifier(criterion='gini', max_depth=10, min_samples_leaf=1, min_samples_split=2)\n",
    "rf = RandomForestClassifier(criterion= 'gini', max_depth= 10, min_samples_leaf= 1, min_samples_split= 5, n_estimators= 150)\n",
    "lr = LogisticRegression(penalty=\"l2\", C=0.001,max_iter= 100, solver='newton-cg')\n",
    "nn = MLPClassifier(hidden_layer_sizes=(10, 10), activation=\"relu\", solver=\"adam\")\n",
    "\n",
    "ensemble_h = VotingClassifier(estimators=[\n",
    "    (\"knn\", knn),\n",
    "    (\"dt\", dt),\n",
    "    (\"rf\", rf),\n",
    "    (\"lr\", lr),\n",
    "    (\"nn\", nn),\n",
    "], voting=\"hard\")\n",
    "\n",
    "ensemble_h.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = ensemble_h.predict(X_train)\n",
    "y_pred_test = ensemble_h.predict(X_test)\n",
    "\n",
    "f1_score_train = f1_score(y_train, y_pred_train, average='macro')\n",
    "f1_score_test = f1_score(y_test, y_pred_test, average='macro')\n",
    "jaccard_score_train = jaccard_score(y_train, y_pred_train, average='macro')\n",
    "jaccard_score_test = jaccard_score(y_test, y_pred_test, average='macro')\n",
    "\n",
    "f1_scores[\"train\"][\"EN_HARD\"] = f1_score_train\n",
    "f1_scores[\"test\"][\"EN_HARD\"] = f1_score_test\n",
    "jaccard_scores[\"train\"][\"EN_HARD\"] = jaccard_score_train\n",
    "jaccard_scores[\"test\"][\"EN_HARD\"] = jaccard_score_test\n",
    "\n",
    "print(\"f1 score on train set:\", f1_score_train)\n",
    "print(\"f1 score on test set:\", f1_score_test)\n",
    "print(\"Jaccard score on train set:\", jaccard_score_train)\n",
    "print(\"Jaccard score on test set:\", jaccard_score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adacae7c",
   "metadata": {},
   "source": [
    "## REPORT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86a5b0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jaccard-training</th>\n",
       "      <th>F1-score-training</th>\n",
       "      <th>Jaccard-testing</th>\n",
       "      <th>F1-score-testing</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.608519</td>\n",
       "      <td>0.733456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.736875</td>\n",
       "      <td>0.837826</td>\n",
       "      <td>0.722517</td>\n",
       "      <td>0.827317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.818106</td>\n",
       "      <td>0.894828</td>\n",
       "      <td>0.787547</td>\n",
       "      <td>0.875440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.541518</td>\n",
       "      <td>0.676135</td>\n",
       "      <td>0.541319</td>\n",
       "      <td>0.675600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>0.759399</td>\n",
       "      <td>0.854671</td>\n",
       "      <td>0.748955</td>\n",
       "      <td>0.847578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hard Voting</th>\n",
       "      <td>0.863776</td>\n",
       "      <td>0.924614</td>\n",
       "      <td>0.789550</td>\n",
       "      <td>0.876690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soft Voting</th>\n",
       "      <td>0.902803</td>\n",
       "      <td>0.947865</td>\n",
       "      <td>0.786571</td>\n",
       "      <td>0.874079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Jaccard-training  F1-score-training  Jaccard-testing  \\\n",
       "Algorithm                                                                   \n",
       "KNN                          1.000000           1.000000         0.608519   \n",
       "Decision Tree                0.736875           0.837826         0.722517   \n",
       "Random Forest                0.818106           0.894828         0.787547   \n",
       "Logistic Regression          0.541518           0.676135         0.541319   \n",
       "Neural Network               0.759399           0.854671         0.748955   \n",
       "Hard Voting                  0.863776           0.924614         0.789550   \n",
       "Soft Voting                  0.902803           0.947865         0.786571   \n",
       "\n",
       "                     F1-score-testing  \n",
       "Algorithm                              \n",
       "KNN                          0.733456  \n",
       "Decision Tree                0.827317  \n",
       "Random Forest                0.875440  \n",
       "Logistic Regression          0.675600  \n",
       "Neural Network               0.847578  \n",
       "Hard Voting                  0.876690  \n",
       "Soft Voting                  0.874079  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_data = {\n",
    "    \"Algorithm\": [\"KNN\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"Neural Network\", \"Hard Voting\", \"Soft Voting\"],\n",
    "    \"Jaccard-training\": jaccard_scores['train'].values(),\n",
    "    \"F1-score-training\": f1_scores['train'].values(),\n",
    "    \"Jaccard-testing\": jaccard_scores['test'].values(),\n",
    "    \"F1-score-testing\": f1_scores['test'].values()\n",
    "}\n",
    "\n",
    "df = pd.DataFrame.from_dict(dict_data)\n",
    "df = df.set_index(\"Algorithm\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db82f720",
   "metadata": {},
   "source": [
    "# Building a Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d05b88fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "266/266 [==============================] - 2s 3ms/step - loss: 0.8581 - accuracy: 0.6683 - val_loss: 0.5267 - val_accuracy: 0.7971\n",
      "Epoch 2/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4674 - accuracy: 0.8293 - val_loss: 0.4627 - val_accuracy: 0.8314\n",
      "Epoch 3/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4248 - accuracy: 0.8432 - val_loss: 0.4219 - val_accuracy: 0.8486\n",
      "Epoch 4/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4042 - accuracy: 0.8542 - val_loss: 0.4112 - val_accuracy: 0.8498\n",
      "Epoch 5/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3844 - accuracy: 0.8626 - val_loss: 0.4048 - val_accuracy: 0.8585\n",
      "Epoch 6/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3736 - accuracy: 0.8680 - val_loss: 0.3917 - val_accuracy: 0.8567\n",
      "Epoch 7/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3611 - accuracy: 0.8717 - val_loss: 0.3840 - val_accuracy: 0.8609\n",
      "Epoch 8/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3600 - accuracy: 0.8719 - val_loss: 0.3852 - val_accuracy: 0.8603\n",
      "Epoch 9/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3523 - accuracy: 0.8728 - val_loss: 0.3791 - val_accuracy: 0.8663\n",
      "Epoch 10/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3440 - accuracy: 0.8802 - val_loss: 0.3873 - val_accuracy: 0.8600\n",
      "Epoch 11/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3388 - accuracy: 0.8802 - val_loss: 0.3953 - val_accuracy: 0.8639\n",
      "Epoch 12/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3373 - accuracy: 0.8800 - val_loss: 0.3698 - val_accuracy: 0.8721\n",
      "Epoch 13/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3299 - accuracy: 0.8844 - val_loss: 0.3816 - val_accuracy: 0.8618\n",
      "Epoch 14/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3303 - accuracy: 0.8822 - val_loss: 0.3681 - val_accuracy: 0.8733\n",
      "Epoch 15/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3232 - accuracy: 0.8866 - val_loss: 0.3686 - val_accuracy: 0.8675\n",
      "Epoch 16/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3206 - accuracy: 0.8873 - val_loss: 0.3825 - val_accuracy: 0.8591\n",
      "Epoch 17/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3202 - accuracy: 0.8862 - val_loss: 0.3766 - val_accuracy: 0.8618\n",
      "Epoch 18/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3154 - accuracy: 0.8871 - val_loss: 0.3775 - val_accuracy: 0.8621\n",
      "Epoch 19/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3122 - accuracy: 0.8890 - val_loss: 0.3700 - val_accuracy: 0.8685\n",
      "Epoch 20/20\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.3076 - accuracy: 0.8896 - val_loss: 0.3777 - val_accuracy: 0.8654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x21a541f3690>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(48, activation='relu'))\n",
    "model.add(Dense(72, activation='relu'))\n",
    "model.add(Dense(48, activation='relu'))\n",
    "model.add(Dense(24, activation='relu'))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c9ac09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 2ms/step - loss: 0.4056 - accuracy: 0.8613\n",
      "Loss on test set: 0.4055521488189697\n",
      "Accuracy on test set: 0.8612716794013977\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Loss on test set:\", loss)\n",
    "print(\"Accuracy on test set:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e249f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82       623\n",
      "           1       0.91      0.84      0.88       518\n",
      "           2       0.69      0.72      0.70       464\n",
      "           3       0.75      0.74      0.74       499\n",
      "           4       0.85      0.83      0.84       600\n",
      "           5       0.94      0.96      0.95       654\n",
      "           6       1.00      0.99      0.99       794\n",
      "\n",
      "    accuracy                           0.86      4152\n",
      "   macro avg       0.85      0.85      0.85      4152\n",
      "weighted avg       0.86      0.86      0.86      4152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred_prob = model.predict(X_test)\n",
    "\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e368abd",
   "metadata": {},
   "source": [
    "### Model Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "143311a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "208/208 [==============================] - 2s 4ms/step - loss: 1.3089 - accuracy: 0.5009 - val_loss: 0.6992 - val_accuracy: 0.7511\n",
      "Epoch 2/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.7587 - accuracy: 0.7035 - val_loss: 0.5048 - val_accuracy: 0.8146\n",
      "Epoch 3/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.6216 - accuracy: 0.7622 - val_loss: 0.4434 - val_accuracy: 0.8423\n",
      "Epoch 4/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.5759 - accuracy: 0.7789 - val_loss: 0.4483 - val_accuracy: 0.8417\n",
      "Epoch 5/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.5514 - accuracy: 0.7997 - val_loss: 0.4155 - val_accuracy: 0.8561\n",
      "Epoch 6/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.5278 - accuracy: 0.8067 - val_loss: 0.4172 - val_accuracy: 0.8558\n",
      "Epoch 7/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.5265 - accuracy: 0.8107 - val_loss: 0.4115 - val_accuracy: 0.8552\n",
      "Epoch 8/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.5089 - accuracy: 0.8213 - val_loss: 0.3941 - val_accuracy: 0.8663\n",
      "Epoch 9/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.8212 - val_loss: 0.4008 - val_accuracy: 0.8582\n",
      "Epoch 10/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.4992 - accuracy: 0.8266 - val_loss: 0.3965 - val_accuracy: 0.8627\n",
      "Epoch 11/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.4855 - accuracy: 0.8334 - val_loss: 0.3935 - val_accuracy: 0.8603\n",
      "Epoch 12/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.4838 - accuracy: 0.8292 - val_loss: 0.3880 - val_accuracy: 0.8624\n",
      "Epoch 13/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.4732 - accuracy: 0.8348 - val_loss: 0.3817 - val_accuracy: 0.8703\n",
      "Epoch 14/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.4743 - accuracy: 0.8353 - val_loss: 0.3815 - val_accuracy: 0.8672\n",
      "Epoch 15/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.4701 - accuracy: 0.8388 - val_loss: 0.3802 - val_accuracy: 0.8663\n",
      "Epoch 16/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.4675 - accuracy: 0.8369 - val_loss: 0.3938 - val_accuracy: 0.8666\n",
      "Epoch 17/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.4615 - accuracy: 0.8383 - val_loss: 0.3867 - val_accuracy: 0.8694\n",
      "Epoch 18/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.4565 - accuracy: 0.8416 - val_loss: 0.3795 - val_accuracy: 0.8733\n",
      "Epoch 19/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.4532 - accuracy: 0.8482 - val_loss: 0.3722 - val_accuracy: 0.8742\n",
      "Epoch 20/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.4478 - accuracy: 0.8400 - val_loss: 0.3879 - val_accuracy: 0.8721\n",
      "Epoch 21/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.4424 - accuracy: 0.8490 - val_loss: 0.3748 - val_accuracy: 0.8751\n",
      "Epoch 22/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.4393 - accuracy: 0.8507 - val_loss: 0.3766 - val_accuracy: 0.8724\n",
      "Epoch 23/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.4388 - accuracy: 0.8503 - val_loss: 0.3816 - val_accuracy: 0.8688\n",
      "Epoch 24/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.4353 - accuracy: 0.8520 - val_loss: 0.3861 - val_accuracy: 0.8730\n",
      "Epoch 25/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.4279 - accuracy: 0.8555 - val_loss: 0.3823 - val_accuracy: 0.8715\n",
      "Epoch 26/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.4319 - accuracy: 0.8533 - val_loss: 0.3802 - val_accuracy: 0.8727\n",
      "Epoch 27/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.4372 - accuracy: 0.8534 - val_loss: 0.3742 - val_accuracy: 0.8706\n",
      "Epoch 28/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.4294 - accuracy: 0.8510 - val_loss: 0.3757 - val_accuracy: 0.8660\n",
      "Epoch 29/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.4269 - accuracy: 0.8546 - val_loss: 0.3718 - val_accuracy: 0.8754\n",
      "Epoch 30/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.4226 - accuracy: 0.8549 - val_loss: 0.3759 - val_accuracy: 0.8748\n",
      "Epoch 31/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.4141 - accuracy: 0.8555 - val_loss: 0.3689 - val_accuracy: 0.8742\n",
      "Epoch 32/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.4115 - accuracy: 0.8596 - val_loss: 0.3792 - val_accuracy: 0.8772\n",
      "Epoch 33/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.4149 - accuracy: 0.8563 - val_loss: 0.3752 - val_accuracy: 0.8742\n",
      "Epoch 34/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.4163 - accuracy: 0.8636 - val_loss: 0.3810 - val_accuracy: 0.8748\n",
      "Epoch 35/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.4095 - accuracy: 0.8622 - val_loss: 0.3804 - val_accuracy: 0.8745\n",
      "Epoch 36/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.4084 - accuracy: 0.8620 - val_loss: 0.3817 - val_accuracy: 0.8727\n",
      "Epoch 37/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.4034 - accuracy: 0.8644 - val_loss: 0.4113 - val_accuracy: 0.8682\n",
      "Epoch 38/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.4094 - accuracy: 0.8591 - val_loss: 0.3854 - val_accuracy: 0.8700\n",
      "Epoch 39/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.3939 - accuracy: 0.8712 - val_loss: 0.3843 - val_accuracy: 0.8675\n",
      "Epoch 40/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.3914 - accuracy: 0.8695 - val_loss: 0.3838 - val_accuracy: 0.8712\n",
      "Epoch 41/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.3981 - accuracy: 0.8675 - val_loss: 0.3903 - val_accuracy: 0.8706\n",
      "Epoch 42/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.3772 - accuracy: 0.8741 - val_loss: 0.3912 - val_accuracy: 0.8706\n",
      "Epoch 43/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.3873 - accuracy: 0.8699 - val_loss: 0.4187 - val_accuracy: 0.8654\n",
      "Epoch 44/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.3857 - accuracy: 0.8732 - val_loss: 0.4015 - val_accuracy: 0.8703\n",
      "Epoch 45/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.3790 - accuracy: 0.8739 - val_loss: 0.4021 - val_accuracy: 0.8694\n",
      "Epoch 46/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.3784 - accuracy: 0.8777 - val_loss: 0.4070 - val_accuracy: 0.8672\n",
      "Epoch 47/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.3728 - accuracy: 0.8772 - val_loss: 0.3948 - val_accuracy: 0.8757\n",
      "Epoch 48/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.3741 - accuracy: 0.8746 - val_loss: 0.4193 - val_accuracy: 0.8763\n",
      "Epoch 49/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.3663 - accuracy: 0.8783 - val_loss: 0.4098 - val_accuracy: 0.8745\n",
      "Epoch 50/50\n",
      "208/208 [==============================] - 1s 3ms/step - loss: 0.3630 - accuracy: 0.8783 - val_loss: 0.4093 - val_accuracy: 0.8682\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Dense(24, input_dim=X_train.shape[1], activation='relu'))\n",
    "model1.add(Dense(48, activation='relu'))\n",
    "model1.add(Dense(72, activation='relu'))\n",
    "model1.add(Dense(48, activation='relu'))\n",
    "model1.add(Dense(24, activation='relu'))\n",
    "\n",
    "model1.add(Dropout(0.5))\n",
    "\n",
    "model1.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model1.fit(X_train, y_train, epochs=50, batch_size=64, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "388f9a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.8699\n",
      "Loss on test set: 0.46901148557662964\n",
      "Accuracy on test set: 0.8699421882629395\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loss, accuracy = model1.evaluate(X_test, y_test)\n",
    "print(\"Loss on test set:\", loss)\n",
    "print(\"Accuracy on test set:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "add547c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83       623\n",
      "           1       0.85      0.96      0.90       518\n",
      "           2       0.71      0.72      0.72       464\n",
      "           3       0.77      0.73      0.75       499\n",
      "           4       0.84      0.84      0.84       600\n",
      "           5       0.96      0.95      0.96       654\n",
      "           6       1.00      0.99      1.00       794\n",
      "\n",
      "    accuracy                           0.87      4152\n",
      "   macro avg       0.86      0.86      0.86      4152\n",
      "weighted avg       0.87      0.87      0.87      4152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_prob = model1.predict(X_test)\n",
    "\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea5a884d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "266/266 [==============================] - 2s 4ms/step - loss: 1.3753 - accuracy: 0.4287 - val_loss: 0.7998 - val_accuracy: 0.6981\n",
      "Epoch 2/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.8897 - accuracy: 0.6198 - val_loss: 0.6204 - val_accuracy: 0.7580\n",
      "Epoch 3/50\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.7667 - accuracy: 0.6809 - val_loss: 0.5757 - val_accuracy: 0.7748\n",
      "Epoch 4/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.7070 - accuracy: 0.7120 - val_loss: 0.5167 - val_accuracy: 0.8098\n",
      "Epoch 5/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.6614 - accuracy: 0.7397 - val_loss: 0.4868 - val_accuracy: 0.8471\n",
      "Epoch 6/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.6215 - accuracy: 0.7552 - val_loss: 0.4593 - val_accuracy: 0.8507\n",
      "Epoch 7/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.6008 - accuracy: 0.7718 - val_loss: 0.4444 - val_accuracy: 0.8621\n",
      "Epoch 8/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.5867 - accuracy: 0.7765 - val_loss: 0.4523 - val_accuracy: 0.8579\n",
      "Epoch 9/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.5513 - accuracy: 0.7988 - val_loss: 0.4304 - val_accuracy: 0.8564\n",
      "Epoch 10/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.5507 - accuracy: 0.7986 - val_loss: 0.4238 - val_accuracy: 0.8573\n",
      "Epoch 11/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.5342 - accuracy: 0.8083 - val_loss: 0.4370 - val_accuracy: 0.8534\n",
      "Epoch 12/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.5197 - accuracy: 0.8106 - val_loss: 0.4222 - val_accuracy: 0.8621\n",
      "Epoch 13/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.5132 - accuracy: 0.8153 - val_loss: 0.4181 - val_accuracy: 0.8642\n",
      "Epoch 14/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.5032 - accuracy: 0.8220 - val_loss: 0.4564 - val_accuracy: 0.8456\n",
      "Epoch 15/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4942 - accuracy: 0.8293 - val_loss: 0.4362 - val_accuracy: 0.8603\n",
      "Epoch 16/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4819 - accuracy: 0.8301 - val_loss: 0.4419 - val_accuracy: 0.8537\n",
      "Epoch 17/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4880 - accuracy: 0.8302 - val_loss: 0.4155 - val_accuracy: 0.8645\n",
      "Epoch 18/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4762 - accuracy: 0.8348 - val_loss: 0.4192 - val_accuracy: 0.8666\n",
      "Epoch 19/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4770 - accuracy: 0.8339 - val_loss: 0.4408 - val_accuracy: 0.8549\n",
      "Epoch 20/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4753 - accuracy: 0.8403 - val_loss: 0.4311 - val_accuracy: 0.8588\n",
      "Epoch 21/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4718 - accuracy: 0.8412 - val_loss: 0.4409 - val_accuracy: 0.8513\n",
      "Epoch 22/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4718 - accuracy: 0.8377 - val_loss: 0.4296 - val_accuracy: 0.8597\n",
      "Epoch 23/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4630 - accuracy: 0.8415 - val_loss: 0.4281 - val_accuracy: 0.8573\n",
      "Epoch 24/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4609 - accuracy: 0.8398 - val_loss: 0.4196 - val_accuracy: 0.8624\n",
      "Epoch 25/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4481 - accuracy: 0.8430 - val_loss: 0.4319 - val_accuracy: 0.8534\n",
      "Epoch 26/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4487 - accuracy: 0.8498 - val_loss: 0.4255 - val_accuracy: 0.8633\n",
      "Epoch 27/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4595 - accuracy: 0.8439 - val_loss: 0.4618 - val_accuracy: 0.8438\n",
      "Epoch 28/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4466 - accuracy: 0.8509 - val_loss: 0.4246 - val_accuracy: 0.8615\n",
      "Epoch 29/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4472 - accuracy: 0.8496 - val_loss: 0.4837 - val_accuracy: 0.8338\n",
      "Epoch 30/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4427 - accuracy: 0.8490 - val_loss: 0.4750 - val_accuracy: 0.8396\n",
      "Epoch 31/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4444 - accuracy: 0.8504 - val_loss: 0.4708 - val_accuracy: 0.8468\n",
      "Epoch 32/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4480 - accuracy: 0.8488 - val_loss: 0.4251 - val_accuracy: 0.8618\n",
      "Epoch 33/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4388 - accuracy: 0.8561 - val_loss: 0.4483 - val_accuracy: 0.8477\n",
      "Epoch 34/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4352 - accuracy: 0.8542 - val_loss: 0.4210 - val_accuracy: 0.8630\n",
      "Epoch 35/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4322 - accuracy: 0.8542 - val_loss: 0.4825 - val_accuracy: 0.8362\n",
      "Epoch 36/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4390 - accuracy: 0.8518 - val_loss: 0.4695 - val_accuracy: 0.8417\n",
      "Epoch 37/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4327 - accuracy: 0.8570 - val_loss: 0.4324 - val_accuracy: 0.8552\n",
      "Epoch 38/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4307 - accuracy: 0.8561 - val_loss: 0.4821 - val_accuracy: 0.8356\n",
      "Epoch 39/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4305 - accuracy: 0.8566 - val_loss: 0.5198 - val_accuracy: 0.8257\n",
      "Epoch 40/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4347 - accuracy: 0.8538 - val_loss: 0.4782 - val_accuracy: 0.8396\n",
      "Epoch 41/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4324 - accuracy: 0.8549 - val_loss: 0.4540 - val_accuracy: 0.8474\n",
      "Epoch 42/50\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.4267 - accuracy: 0.8551 - val_loss: 0.4468 - val_accuracy: 0.8561\n",
      "Epoch 43/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4255 - accuracy: 0.8546 - val_loss: 0.4054 - val_accuracy: 0.8672\n",
      "Epoch 44/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4297 - accuracy: 0.8577 - val_loss: 0.4735 - val_accuracy: 0.8347\n",
      "Epoch 45/50\n",
      "266/266 [==============================] - 1s 4ms/step - loss: 0.4218 - accuracy: 0.8588 - val_loss: 0.4354 - val_accuracy: 0.8531\n",
      "Epoch 46/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4175 - accuracy: 0.8604 - val_loss: 0.4931 - val_accuracy: 0.8432\n",
      "Epoch 47/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4195 - accuracy: 0.8595 - val_loss: 0.4660 - val_accuracy: 0.8471\n",
      "Epoch 48/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4253 - accuracy: 0.8571 - val_loss: 0.5133 - val_accuracy: 0.8152\n",
      "Epoch 49/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4216 - accuracy: 0.8579 - val_loss: 0.4736 - val_accuracy: 0.8492\n",
      "Epoch 50/50\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 0.4218 - accuracy: 0.8599 - val_loss: 0.5104 - val_accuracy: 0.8188\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(24, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(48, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(72, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(48, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(24, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=50, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f85ee02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 2ms/step - loss: 0.5549 - accuracy: 0.8092\n",
      "Loss on test set: 0.5549184083938599\n",
      "Accuracy on test set: 0.8092485666275024\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Loss on test set:\", loss)\n",
    "print(\"Accuracy on test set:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a83fdf10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83       623\n",
      "           1       0.85      0.96      0.90       518\n",
      "           2       0.71      0.72      0.72       464\n",
      "           3       0.77      0.73      0.75       499\n",
      "           4       0.84      0.84      0.84       600\n",
      "           5       0.96      0.95      0.96       654\n",
      "           6       1.00      0.99      1.00       794\n",
      "\n",
      "    accuracy                           0.87      4152\n",
      "   macro avg       0.86      0.86      0.86      4152\n",
      "weighted avg       0.87      0.87      0.87      4152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_prob = model1.predict(X_test)\n",
    "\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aedf5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63d7397",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
